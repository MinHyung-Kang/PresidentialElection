{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get a smaller, more significant portion of the edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of original edges : 295761\n",
      "Number of reduced edges : 20631\n",
      "Number of original edges : 339930\n",
      "Number of reduced edges : 24162\n",
      "Number of original edges : 413056\n",
      "Number of reduced edges : 24258\n"
     ]
    }
   ],
   "source": [
    "import codecs\n",
    "import csv\n",
    "import os\n",
    "\n",
    "names = ['HillaryClinton','BernieSanders','DonaldTrump']\n",
    "fileType = 'EdgesFrequency'#,'MentionFreq','ReplyFreq','RetweetFreq']\n",
    "\n",
    "# Read in each candidates edge files,\n",
    "# Combine them and save them\n",
    "for i in range(len(names)) :\n",
    "    fileNameOnly = \"./FinalData/%s\" %(names[i])\n",
    "    fileRead = \"%s%s.csv\" %(fileNameOnly, fileType)\n",
    "    fileOut = \"%s%s%s.csv\" %(fileNameOnly, fileType, 'Reduced')\n",
    "    with open(fileRead, 'rb') as f:\n",
    "        reader = csv.reader(f)\n",
    "        data_ori = list(reader)\n",
    "    print ('Number of original edges : %d') %(len(data_ori))\n",
    "    \n",
    "    counter= 0\n",
    "    with open(fileOut,'wb') as fp:    \n",
    "        a = csv.writer(fp,delimiter=',')\n",
    "        for i in range(len(data_ori)):\n",
    "            if(int(data_ori[i][2]) > 2 ):\n",
    "                counter += 1\n",
    "                a.writerow(data_ori[i])\n",
    "                \n",
    "    print ('Number of reduced edges : %d') %(counter)\n",
    "\n",
    "#             data_sorted = sorted(data_list_raw, key = lambda x:int(x[1]), reverse = True)\n",
    "#             print fileRead\n",
    "#             for index in range(5):\n",
    "#                 print(data_sorted[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make the matrix symmetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of symmetric edges : 20511\n",
      "Number of symmetric edges : 24011\n",
      "Number of symmetric edges : 24130\n"
     ]
    }
   ],
   "source": [
    "import codecs\n",
    "import csv\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "names = ['HillaryClinton','BernieSanders','DonaldTrump']\n",
    "fileType = 'EdgesFrequencyReduced'#,'MentionFreq','ReplyFreq','RetweetFreq']\n",
    "\n",
    "# Read in each candidates edge files,\n",
    "# Combine them and save them\n",
    "for i in range(len(names)) :\n",
    "    fileNameOnly = \"./FinalData/%s\" %(names[i])\n",
    "    fileRead = \"%s%s.csv\" %(fileNameOnly, fileType)\n",
    "    fileOut = \"%s%s%s.csv\" %(fileNameOnly, fileType, 'Symmetric')\n",
    "    with open(fileRead, 'rb') as f:\n",
    "        reader = csv.reader(f)\n",
    "        data_ori = list(reader)\n",
    "        \n",
    "    edges = defaultdict(dict)\n",
    "    with open(fileOut,'wb') as fp:    \n",
    "        a = csv.writer(fp,delimiter=',')\n",
    "        for i in range(len(data_ori)):\n",
    "            if(data_ori[i][0]<=data_ori[i][1]):\n",
    "                fromNode = data_ori[i][0]\n",
    "                toNode = data_ori[i][1]\n",
    "            else:\n",
    "                fromNode = data_ori[i][1]\n",
    "                toNode = data_ori[i][0]\n",
    "            weight = data_ori[i][2]\n",
    "            \n",
    "            if fromNode in edges.keys():\n",
    "                if(toNode in edges[fromNode].keys()):\n",
    "                    edges[fromNode][toNode] += int(weight)\n",
    "                else: \n",
    "                    edges[fromNode][toNode] = int(weight)\n",
    "            else:\n",
    "                edges[fromNode][toNode] = int(weight)\n",
    "        \n",
    "        counter = 0\n",
    "        for fromNodes in edges.keys():\n",
    "            for toNodes in edges[fromNodes].keys():\n",
    "                counter += 1\n",
    "                a.writerow( [fromNodes, toNodes, edges[fromNodes][toNodes]])\n",
    "                \n",
    "        print ('Number of symmetric edges : %d') %counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "836\n"
     ]
    }
   ],
   "source": [
    "import codecs\n",
    "import csv\n",
    "import os\n",
    "\n",
    "names = ['HillaryClinton']#,'BernieSanders','DonaldTrump']\n",
    "fileType = 'EdgesFrequencyReduced'#,'MentionFreq','ReplyFreq','RetweetFreq']\n",
    "\n",
    "# Read in each candidates edge files,\n",
    "# Combine them and save them\n",
    "for i in range(len(names)) :\n",
    "    fileNameOnly = \"./FinalData/%s\" %(names[i])\n",
    "    fileRead = \"%s%s%s.csv\" %(fileNameOnly, fileType, 'Symmetric')\n",
    "    with open(fileRead, 'rb') as f:\n",
    "        reader = csv.reader(f)\n",
    "        data_ori = list(reader)\n",
    "    weights = []\n",
    "    for i in range(len(data_ori)):\n",
    "        weights.append(int(data_ori[i][2]))\n",
    "    print max(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Relabel the matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing HillaryClinton\n",
      "File Read\n",
      "1000\n",
      "2000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "13000\n",
      "Converted and Saved\n",
      "Index Saved\n",
      "Processing BernieSanders\n",
      "File Read\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "6000\n",
      "6000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "12000\n",
      "13000\n",
      "Converted and Saved\n",
      "Index Saved\n",
      "Processing DonaldTrump\n",
      "File Read\n",
      "1000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "Converted and Saved\n",
      "Index Saved\n"
     ]
    }
   ],
   "source": [
    "import codecs\n",
    "import csv\n",
    "import os\n",
    "\n",
    "names = ['HillaryClinton','BernieSanders','DonaldTrump']\n",
    "fileType = 'EdgesFrequencyReduced'#,'MentionFreq','ReplyFreq','RetweetFreq']\n",
    "\n",
    "# Read in each candidates edge files,\n",
    "# Combine them and save them\n",
    "for i in range(len(names)) :\n",
    "    fileNameOnly = \"./FinalData/%s\" %(names[i])\n",
    "    fileRead = \"%s%s%s.csv\" %(fileNameOnly, fileType, 'Symmetric')\n",
    "    fileWrite = \"%s%s%s.csv\" %(fileNameOnly, fileType, 'SymmetricNewLabel')\n",
    "    fileIndex = \"%s%s%s.csv\" %(fileNameOnly, fileType, 'SymmetricIndex')\n",
    "    \n",
    "    print 'Processing %s' %names[i]\n",
    "    \n",
    "    with open(fileRead, 'rb') as f:\n",
    "        reader = csv.reader(f)\n",
    "        data = list(reader)\n",
    "        \n",
    "    print 'File Read' \n",
    "         \n",
    "    ids = {}\n",
    "    counter = 1\n",
    "    with open(fileWrite,'wb') as fp:    \n",
    "        a = csv.writer(fp,delimiter=',') \n",
    "        for index in range(len(data)):\n",
    "            if (counter % 1000 == 0) :\n",
    "                print counter\n",
    "            if (data[index][0] not in ids.keys()) :\n",
    "                ids[data[index][0]] = counter\n",
    "                first = counter\n",
    "                counter += 1\n",
    "            else : \n",
    "                first = ids[data[index][0]]\n",
    "            if (data[index][1] not in ids.keys()):\n",
    "                ids[data[index][1]] = counter\n",
    "                second = counter\n",
    "                counter += 1\n",
    "            else : \n",
    "                second = ids[data[index][1]]\n",
    "            a.writerow([first,second,data[index][2]])\n",
    "            \n",
    "    print 'Converted and Saved'\n",
    "            \n",
    "    with open(fileIndex,'wb') as fp:    \n",
    "        a = csv.writer(fp,delimiter=',') \n",
    "        keys = ids.keys()\n",
    "        keys = sorted(keys)\n",
    "        for key in keys:\n",
    "            a.writerow([key, ids[key]])\n",
    "    \n",
    "    print 'Index Saved'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert the userSentimentFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing HillaryClinton\n",
      "Data Read\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "Converted and Saved\n",
      "Index File Read\n",
      "Processing BernieSanders\n",
      "Data Read\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "Converted and Saved\n",
      "Index File Read\n",
      "Processing DonaldTrump\n",
      "Data Read\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "Converted and Saved\n",
      "Index File Read\n"
     ]
    }
   ],
   "source": [
    "import codecs\n",
    "import csv\n",
    "import os\n",
    "\n",
    "names = ['HillaryClinton','BernieSanders','DonaldTrump']\n",
    "fileType = 'EdgesFrequencyReduced'#,'MentionFreq','ReplyFreq','RetweetFreq']\n",
    "\n",
    "# Read in each candidates edge files,\n",
    "# Combine them and save them\n",
    "for i in range(len(names)) :\n",
    "    fileNameOnly = \"./FinalData/%s\" %(names[i])\n",
    "    fileIndex = \"%s%s.csv\" %(fileNameOnly, 'UserSentimentIndex')\n",
    "    fileRead = \"%s%s.csv\" %(fileNameOnly, 'UserSentiment')\n",
    "    fileWrite = \"%s%s.csv\" %(fileNameOnly, 'UserSentimentNewLabel')\n",
    "    \n",
    "    \n",
    "    print 'Processing %s' %names[i]        \n",
    "    \n",
    "    with open(fileRead, 'rb') as f:\n",
    "        reader = csv.reader(f)\n",
    "        data = list(reader)\n",
    "    \n",
    "    print 'Data Read' \n",
    "    \n",
    "    index = {}\n",
    "\n",
    "    counter = 1\n",
    "    with open(fileWrite,'wb') as fp:    \n",
    "        a = csv.writer(fp,delimiter=',') \n",
    "        for loc in range(len(data)):\n",
    "            if (counter % 1000 == 0) :\n",
    "                print counter            \n",
    "            row = data[loc]\n",
    "            \n",
    "            if (row[0] in index.keys()):\n",
    "                newId = index[row[0]]\n",
    "            else:\n",
    "                index[row[0]] = counter\n",
    "                newId = counter\n",
    "                counter += 1\n",
    "            a.writerow([newId,row[1],row[2],row[3]])\n",
    "    print 'Converted and Saved'\n",
    "    \n",
    "    with open(fileIndex,'wb') as fp:    \n",
    "        a = csv.writer(fp,delimiter=',') \n",
    "        keys = index.keys()\n",
    "        keys = sorted(keys)\n",
    "        for key in keys:\n",
    "            a.writerow([key, index[key]])\n",
    "        \n",
    "    print 'Index File Read' \n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert From sentiment to edges unique indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "a = range(1,4)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing HillaryClinton\n",
      "Processing BernieSanders\n",
      "Processing DonaldTrump\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import codecs\n",
    "import unicodecsv as csv\n",
    "import os\n",
    "\n",
    "names = ['HillaryClinton','BernieSanders','DonaldTrump']\n",
    "fileReadOneName = 'UserSentimentIndex'\n",
    "fileReadTwoName = 'EdgesFrequencyReducedSymmetricIndex'\n",
    "fileDictName = 'SentimentToEdgeIndex'\n",
    "fileClassesName = 'Clustering_k5'\n",
    "fileOutputName = 'ClusteringClass'\n",
    "lengths = [13925,13893,16348]\n",
    "\n",
    "\n",
    "for i in range(len(names)):\n",
    "    fileReadOne = './FinalData/%s%s.csv' %(names[i],fileReadOneName)\n",
    "    fileReadTwo = './FinalData/%s%s.csv' %(names[i],fileReadTwoName)\n",
    "    fileDict = './FinalData/%s%s.csv' %(names[i],fileDictName)\n",
    "    fileClasses = './FinalData/%s%s.csv' %(names[i],fileClassesName)\n",
    "    fileOutput = './FinalData/%s%s.csv' %(names[i],fileOutputName)\n",
    "    \n",
    "    print 'Processing %s' %(names[i])\n",
    "    \n",
    "    # Index change between edges and original\n",
    "    with open(fileReadTwo, 'rb') as f:\n",
    "        reader = csv.reader(f)\n",
    "        data= list(reader)\n",
    "    \n",
    "    ori_to_edges = {}\n",
    "    for n in range(len(data)):\n",
    "        ori_to_edges[data[n][0]] = int(data[n][1])\n",
    "    \n",
    "    # Index changes between sentiment and original\n",
    "    with open(fileReadOne, 'rb') as f:\n",
    "        reader = csv.reader(f)\n",
    "        data= list(reader)\n",
    "    \n",
    "    sentiment_to_edge = {}\n",
    "    for n in range(len(data)):\n",
    "        sentiment_to_edge[int(data[n][1])] = ori_to_edges[data[n][0]]\n",
    "        \n",
    "        \n",
    "    with open(fileClasses, 'rb') as f:\n",
    "        reader = csv.reader(f)\n",
    "        data= list(reader)\n",
    "    \n",
    "    classify_user = {}\n",
    "    for n in range(len(data)):\n",
    "        classify_user[int(sentiment_to_edge[int(data[n][0])])] = data[n][1]\n",
    "        \n",
    "    keys = classify_user.keys()\n",
    "    \n",
    "    with open(fileOutput,'wb') as fp:    \n",
    "        a = csv.writer(fp,delimiter=',')\n",
    "        for n in range(1,lengths[i]+1):\n",
    "            if (n in keys):\n",
    "                a.writerow([n, classify_user[n]])\n",
    "            else:\n",
    "                a.writerow([n,0])\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
